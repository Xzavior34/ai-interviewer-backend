# ğŸš€ AI Interview Screener (Backend)

![Python](https://img.shields.io/badge/Python-3.9%2B-blue.svg)
![FastAPI](https://img.shields.io/badge/FastAPI-0.109.0-teal.svg)
![Architecture](https://img.shields.io/badge/Architecture-Microservice-orange)
![Docker](https://img.shields.io/badge/Docker-Ready-blue)
![Coverage](https://img.shields.io/badge/Tests-Passing-green)

A high-performance, asynchronous backend service designed to automate the technical screening process. This microservice accepts candidate answers, utilizes an LLM for semantic evaluation, and ranks candidates concurrently.

---

## ğŸ“– Table of Contents
- [System Architecture](#-system-architecture)
- [Project Structure](#-project-structure)
- [Key Features](#-key-features)
- [Installation & Setup](#-installation--setup)
- [API Reference](#-api-reference)
- [Design Decisions (The "Why")](#-design-decisions)
- [Future Roadmap](#-future-roadmap)

---

## ğŸ— System Architecture

The application follows a **Service-Layer Pattern** to decouple business logic from the HTTP transport layer. The diagram below illustrates the asynchronous data flow.

```mermaid
graph LR
    A[Client] -->|POST JSON| B(FastAPI Router)
    B -->|Validate| C{Pydantic Models}
    C -->|Valid Data| D[Service Layer]
    D -->|Async Request| E[OpenAI GPT-3.5]
    E -->|JSON Response| D
    D -->|Result| A
    style C fill:#f9f,stroke:#333,stroke-width:2px
    style E fill:#bbf,stroke:#333,stroke-width:2px
```

## ğŸ“‚Project Structure
```
/ai-interviewer-backend
â”‚
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py            # Application Entry Point & Routes
â”‚   â”œâ”€â”€ models.py          # Pydantic Schemas (Strict Data Contracts)
â”‚   â”œâ”€â”€ services.py        # Business Logic (LLM Integration & Ranking)
â”‚   â””â”€â”€ config.py          # Environment Configuration
â”‚
â”œâ”€â”€ tests/                 # Pytest Suite
â”œâ”€â”€ Dockerfile             # Containerization
â”œâ”€â”€ requirements.txt       # Dependencies
â””â”€â”€ README.md              # Documentation
```
## âœ¨ Key Features
â€‹ğŸ›¡ï¸ Strict Type Safety: Leverages Pydantic for rigorous request/response validation. Prevents "garbage in" data from reaching the logic layer.
â€‹ğŸ¯ Deterministic AI Outputs: Utilizes OpenAI's response_format={"type": "json_object"} to guarantee the LLM returns parseable JSON, eliminating brittle regex parsing.
â€‹âš¡ High-Concurrency Ranking: The /rank-candidates endpoint uses asyncio.gather to process generic candidate batches in parallel.
â€‹Impact: Latency is bounded by the slowest single request (O(1)), rather than the sum of all requests (O(n)).
â€‹ğŸ“¦ Production Ready: Includes strict error handling, environment configuration via .env, and Docker containerization.
â€‹ğŸ›  Installation & Setup
â€‹Prerequisites
â€‹Python 3.9+
â€‹Docker (Optional)
â€‹OpenAI API Key
## 1.Clone the repository
git clone [https://github.com/Xzavior34/ai-interviewer-backend.git](https://github.com/Xzavior34/ai-interviewer-backend.git)
cd ai-interviewer-backend
## 2. Set up Environment
â€‹Create a .env file in the root directory and add your key:
# .env
OPENAI_API_KEY=sk-your-actual-api-key-here
## 3. Install Dependencies
pip install -r requirements.txt
## 4. Run the Server
uvicorn app.main:app --reload
Server will start at http://localhost:8000
## â€‹ğŸ§  Design Decisions
â€‹1. Why FastAPI over Node.js?
â€‹While Node.js is excellent for I/O-bound tasks, FastAPI was selected for specific architectural advantages:
â€‹Data Integrity: The integration with Pydantic ensures that data contracts are enforced before code execution. In an API handling external AI inputs, validation is the first line of defense.
â€‹Native AI Ecosystem: Python is the lingua franca of AI. If we need to expand this later to use LangChain, local HuggingFace models, or RAG (Retrieval Augmented Generation), Python libraries are superior.
â€‹Async Performance: Python's modern async/await syntax handles the latency of LLM API calls just as efficiently as Node's Event Loop.
â€‹2. Why GPT-3.5-Turbo + JSON Mode?
â€‹Reliability: Generative models are notoriously difficult to parse programmatically. By enforcing json_object mode, we shift the burden of structure from the application logic to the model itself.
â€‹Cost/Efficiency: For a screening task, GPT-4 is overkill. GPT-3.5-Turbo provides the optimal balance of reasoning capability and latency/cost.
##â€‹ğŸ§ª  Running Tests
â€‹Quality assurance is handled via pytest. We prioritize testing validation logic and endpoint health.
pytest
## ğŸ—º Future Roadmap (Improvements)
â€‹[ ] Rate Limiting: Implement slowapi to prevent API abuse.
â€‹[ ] Database Integration: Persist candidate scores using PostgreSQL/SQLAlchemy.
â€‹[ ] Caching: Use Redis to cache results for identical answers to save on API costs.
â€‹Built with â¤ï¸ by Philip Inem
